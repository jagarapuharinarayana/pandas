{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a766ad5-7b9d-4b26-b6f6-d658272af320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6901749e-1fe6-4aff-8de4-1adec5f8536f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fab93935-577c-4980-a24e-ddae906fc60e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'data.xlsx',\n",
       " 'etc',\n",
       " 'Include',\n",
       " 'Lib',\n",
       " 'pyvenv.cfg',\n",
       " 'Scripts',\n",
       " 'share',\n",
       " 'Untitled.ipynb']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cc2cdd2-8188-4841-875f-28fc401f0567",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel(r\"data.xlsx\",sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9f6c597d-e061-47d8-80c7-7fe7556b700a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex=[]\n",
    "for i in df['Mydata']:\n",
    "    ex.append(i[-6:])\n",
    "    # print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e4f71d0f-fbf9-4d1f-9013-7e3a1a1254de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                     3 Getting Started\n",
       "1                     ·          scrapy commands (3:14)\n",
       "2           ·          Scrapy Shell Introduction (6:27)\n",
       "3                             4 The First Scrapy Spider\n",
       "4            ·          What information we need (5:05)\n",
       "                            ...                        \n",
       "87                                         17 Debugging\n",
       "88      ·          Debugging - Print and Logging (6:39)\n",
       "89      ·          Debugging - Browser and Shell (5:16)\n",
       "90    ·          Running Spider as a Python Script (...\n",
       "91    ·          Running Project as a Python Script ...\n",
       "Name: Mydata, Length: 92, dtype: object"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Mydata']\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "04e227c9-a374-4ba8-8c8e-3678752a1b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Introduction to Logging \n",
      " Logging In Action \n",
      " Scrapy Architecture \n",
      " Scrapy Projects \n",
      " Real Life Example \n",
      " About Robots.txt \n",
      " HTTP Headers \n",
      " Headers in Scrapy \n",
      " Default Reuqest Headers and Bonus Tip \n",
      " Exporting Amazon Data \n",
      " Extracting Data with Shell \n",
      " Pagination \n",
      " Exercise - Section 9 \n",
      " Solution to Exercise - Section 9 \n",
      " Items \n",
      " Spider with Unclean Data \n",
      " Item Loader \n",
      " Output Processor \n",
      " Input Processor \n",
      " HTTP Get vs POST \n",
      " POST using scrapy.Request \n",
      " FormRequest \n",
      " Login using FormRequest \n",
      " from_response \n",
      " Exercise - Real Job Posting \n",
      " Exercise Solution \n",
      " Infinite Scroll \n",
      " Next Page Link \n",
      " Pagination in Amazon \n",
      " When to avoid Pagination \n",
      " 13.1 Introduction To Crawl Spiders \n",
      " 13.2 Our First Crawl Spider \n",
      " 13.3 Anatomy of a Rule \n",
      " 13.4 Controlling Link Extractor \n",
      " 13.4 Power of Crawl Spiders \n",
      " 13.6 More Rules \n",
      " Introduction to Pipelines \n",
      " Structure of a Pipeline \n",
      " Pipeline Demonstration \n",
      " Cleaning Up Data \n",
      " Multiple pipelines in the SAME Project \n",
      " Introducing File and Image Pipelines \n",
      " File Download Step 1 - Preparing Spider \n",
      " File Download Step 2 - Enabling the Pipeline \n",
      " Changing the filenames \n",
      " Download Images \n",
      " Changing Image Names \n",
      " Generating Image Thumbnails \n",
      " Export to Files \n",
      " Export to Excel - Planning and Setting Up \n",
      " Export to Excel - Inserting Items \n",
      " Saving to SQLite - Planning and Setting Up \n",
      " Saving to SQLite - Inserting Items \n",
      " Debugging - Print and Logging \n",
      " Debugging - Browser and Shell \n",
      " Running Spider as a Python Script \n",
      " Running Project as a Python Script \n"
     ]
    }
   ],
   "source": [
    "for i in df['Mydata']:\n",
    "    print(i[10:][:-6].strip('('))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "68234f37-c0bf-457e-bbe8-96db50f155c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Mydata'], dtype='object')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "52bec95b-1af3-4ee6-aef0-7c142db433d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05:05:00\n",
      "03:36:00\n",
      "03:32:00\n",
      "06:52:00\n",
      "03:32:00\n",
      "05:51:00\n",
      "03:35:00\n",
      "00:34:00\n",
      "07:40:00\n",
      "nan\n",
      "nan\n",
      "05:07:00\n",
      "07:23:00\n",
      "08:12:00\n",
      "05:50:00\n",
      "08:17:00\n",
      "nan\n",
      "nan\n",
      "06:21:00\n",
      "07:23:00\n",
      "09:28:00\n",
      "09:29:00\n",
      "nan\n",
      "nan\n",
      "03:41:00\n",
      "10:33:00\n",
      "nan\n",
      "nan\n",
      "05:24:00\n",
      "08:14:00\n",
      "nan\n",
      "nan\n",
      "05:36:00\n",
      "05:08:00\n",
      "02:35:00\n",
      "09:27:00\n",
      "06:59:00\n",
      "11:42:00\n",
      "04:37:00\n",
      "11:19:00\n",
      "00:58:00\n",
      "17:29:00\n",
      "nan\n",
      "nan\n",
      "04:57:00\n",
      "05:51:00\n",
      "06:54:00\n",
      "05:47:00\n",
      "09:45:00\n",
      "nan\n",
      "nan\n",
      "07:19:00\n",
      "09:36:00\n",
      "03:38:00\n",
      "10:14:00\n",
      "03:55:00\n",
      "00:48:00\n",
      "10:05:00\n",
      "nan\n",
      "nan\n",
      "07:59:00\n",
      "06:27:00\n",
      "05:11:00\n",
      "09:52:00\n",
      "nan\n",
      "nan\n",
      "03:15:00\n",
      "04:17:00\n",
      "07:35:00\n",
      "07:21:00\n",
      "03:48:00\n",
      "05:11:00\n",
      "nan\n",
      "nan\n",
      "04:15:00\n",
      "03:17:00\n",
      "07:48:00\n",
      "07:24:00\n",
      "07:26:00\n",
      "nan\n",
      "nan\n",
      "03:59:00\n",
      "08:27:00\n",
      "03:02:00\n",
      "06:04:00\n",
      "05:17:00\n",
      "04:35:00\n",
      "06:24:00\n",
      "nan\n",
      "nan\n",
      "09:39:00\n",
      "09:09:00\n",
      "07:23:00\n",
      "08:00:00\n",
      "11:33:00\n",
      "nan\n",
      "nan\n",
      "06:39:00\n",
      "05:16:00\n",
      "04:24:00\n",
      "02:32:00\n"
     ]
    }
   ],
   "source": [
    "for i in df['Time']:\n",
    "    print(i[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a9141f0c-d341-4a65-8ad9-b6f5ceba258d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0].values[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b004c778-2ceb-4d90-9936-1dfec4e6b5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Getting Started\n",
      "4 The First Scrapy Spider\n",
      "5 CSS Selectors\n",
      "6 XPath: Everything You Need to Know!\n",
      "7 Logging\n",
      "8 Scrapy Architecture and Projects\n",
      "9 Real-Life Example: Amazon\n",
      "10 Items and Item Loaders\n",
      "11 HTTP Post, Submit Form, and Login\n",
      "12 Pagination\n",
      "13 Crawl Spiders\n",
      "14 Item Pipeline\n",
      "15 Downloading Files and Images\n",
      "16 Exporting Data\n",
      "17 Debugging\n"
     ]
    }
   ],
   "source": [
    "for i in df['Mydata']:\n",
    "    if(i.strip()[0]) in [str(j) for j in list(range(1,10)) ]:\n",
    "        continue\n",
    "    else:\n",
    "        print(\"00:\"+i.replace('·\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 \\xa0','').strip()[-6:].strip('()'))\n",
    "        # print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba0d6a9f-1d7a-4394-aeed-9e1646060386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '3', '4', '5', '6', '7', '8']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[str(j) for j in list(range(1,9)) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c78f3f79-0526-4f6e-9ab0-d71ea4527c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'·\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 \\xa0Running Project as a Python Script (2:32)'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c30bcba4-5db6-4803-8d0c-cef03aa50d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                     3 Getting Started\n",
       "1                     ·          scrapy commands (3:14)\n",
       "2           ·          Scrapy Shell Introduction (6:27)\n",
       "3                             4 The First Scrapy Spider\n",
       "4            ·          What information we need (5:05)\n",
       "                            ...                        \n",
       "87                                         17 Debugging\n",
       "88      ·          Debugging - Print and Logging (6:39)\n",
       "89      ·          Debugging - Browser and Shell (5:16)\n",
       "90    ·          Running Spider as a Python Script (...\n",
       "91    ·          Running Project as a Python Script ...\n",
       "Name: Mydata, Length: 92, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Mydata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a823fee-8638-4acb-aa37-3a52ee7904dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d54f35e-86d3-4dc2-8d34-02e299d2e8b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b0c248-cd3e-40f3-8f27-8a823d79b4da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a241332-13b8-4eb0-9e3c-e48fe2b6c87a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8ccab2-2b24-4d1c-ad38-12b0c9d418e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a12d597-337f-4434-8203-60406505d927",
   "metadata": {},
   "outputs": [],
   "source": [
    " Initialize a variable to keep track of the current section group\n",
    "current_group = []\n",
    "section_groups = []\n",
    "\n",
    "for index, row in Mydata.iterrows():\n",
    "    section_title = row['']\n",
    "    # Check if the section starts with a number\n",
    "    if section_title[0].isdigit():\n",
    "        current_group = [section_title]\n",
    "    elif current_group:\n",
    "        current_group.append(section_title)\n",
    "        section_groups.append(current_group)\n",
    "    else:\n",
    "        section_groups.append([section_title])\n",
    "\n",
    "# Display the grouped sections\n",
    "for group in section_groups:\n",
    "    print(group)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
